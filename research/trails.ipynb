{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bit/Medical-assistance-chatbot/research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bit/Medical-assistance-chatbot'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_file(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                             glob = \"*pdf\",\n",
    "                             loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data = load_pdf_file(data = 'Data/')\n",
    "#rerun the above line to load the pdf files again if cache is cleared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cached_data.joblib']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import joblib\n",
    "# joblib.dump(extracted_data, 'cached_data.joblib')\n",
    "#for caching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# Load the cached data\n",
    "extracted_data = joblib.load('cached_data.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    \n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text chunks:  3424\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"Length of text chunks: \", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_embedding_model():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings\n",
    "#returns the embedding model which is used to convert the text chunks into vectors\n",
    "#it gives 384 dimensional vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30.1\n"
     ]
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "print(huggingface_hub.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of query results:  384\n"
     ]
    }
   ],
   "source": [
    "query_results = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length of query results: \", len(query_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03447728976607323,\n",
       " 0.03102320060133934,\n",
       " 0.006734994240105152,\n",
       " 0.026108931750059128,\n",
       " -0.039361972361803055]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY # for authentication\n",
    "# for authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'medicalbot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pinecone import Pinecone, ServerlessSpec\n",
    "# pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# pc.create_index(\n",
    "#     name='medicalbot',\n",
    "#     dimension=384,  # dimension of your embeddings\n",
    "#     metric='cosine',\n",
    "#     spec=ServerlessSpec(\n",
    "\n",
    "#         cloud=\"aws\",\n",
    "\n",
    "#         region=\"us-east-1\"\n",
    "\n",
    "#     ) \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enbed each text chunk and upsert the embeddings into the Pinecone index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents = text_chunks,\n",
    "    index_name = index_name,\n",
    "    embedding = embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load existing index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name = index_name,\n",
    "    embedding = embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x743b23f9b5b0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type = \"similarity\", search_kwargs = {\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is acne?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='66e3d95e-780a-4d52-9ce6-7e543e181a1c', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 47.0, 'page_label': '48', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data/Medical_book.pdf', 'total_pages': 637.0}, page_content='KEY TERMS\\nAdenoma —A type of noncancerous (benign)\\ntumor that often involves the overgrowth of certain\\ncells found in glands.\\nGland—A collection of cells that releases certain\\nchemicals, or hormones, that are important to the\\nfunctioning of other organs or body systems.\\nHormone —A chemical produced in one part of\\nthe body that travels to another part of the body in\\norder to exert an effect.\\nHypothalamus —A structure within the brain\\nresponsible for a large number of normal functions\\nthroughout the body, including regulating sleep,\\ntemperature, eating, and sexual development. The\\nhypothalamus also regulates the functions of the\\npituitary gland by directing the pituitary to stop or\\nstart production of its hormones.\\nPituitary—A gland located at the base of the brain\\nthat produces a number of hormones, including\\nthose that regulate growth and reproductive func-\\ntions. Overproduction of the pituitary hormone\\ncalled growth hormone (GH) is responsible for the\\ncondition known as acromegaly.'),\n",
       " Document(id='51c5a9be-5577-4fdf-b872-f3f42c7831d5', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 62.0, 'page_label': '63', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data/Medical_book.pdf', 'total_pages': 637.0}, page_content='lems, inability to concentrate, and being easily startled.\\nDiagnosis\\nDiagnosis of acute stress disorder is based on a com-\\nbination of the patient’s history and a physical examina-\\ntion to rule out diseases that can cause anxiety. The\\nKEY TERMS\\nDepersonalization —A dissociative symptom in\\nwhich the patient feels that his or her body is unre-\\nal, is changing, or is dissolving.\\nDerealization —A dissociative symptom in which\\nthe external environment is perceived as unreal.\\nDissociation —A reaction to trauma in which the\\nmind splits off certain aspects of the trauma from\\nconscious awareness. Dissociation can affect the\\npatient’s memory, sense of reality, and sense of\\nidentity.\\nTrauma—In the context of ASD, a disastrous or\\nlife-threatening event.\\nessential feature is a traumatic event within one month of\\nthe onset of symptoms. Other diagnostic criteria include:\\n• The symptoms significantly interfere with normal\\nsocial or vocational functioning'),\n",
       " Document(id='bae958c3-7e8a-4d04-a323-67099216b39c', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 317.0, 'page_label': '318', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data/Medical_book.pdf', 'total_pages': 637.0}, page_content='virus infections.\\nBioavailability —A measure of the amount of drug\\nthat is actually absorbed from a given dose.\\nImmune system —The body’s natural defenses\\nagainst disease and infection.\\nInflammation —Pain, redness, swelling, and heat\\nthat usually develop in response to injury or illness.\\nInsomnia —A sleep disorder characterized by\\ninability to either fall asleep or to stay asleep.\\nMutates—Undergoes a spontaneous change in the\\nmake-up of genes or chromosomes.\\nPancreas—A gland located beneath the stomach.\\nThe pancreas produces juices that help break down\\nfood and secretes insulin that helps the body use\\nsugar for energy.\\nPregnancy category—A system of classifying drugs\\naccording to their established risks for use during\\npregnancy. Category A: Controlled human studies\\nhave demonstrated no fetal risk. Category B: Animal\\nstudies indicate no fetal risk, but no human studies;\\nor adverse effects in animals, but not in well-con-\\ntrolled human studies. Category C: No adequate')]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Models:\n",
      "Name: models/chat-bison-001\n",
      "Display Name: PaLM 2 Chat (Legacy)\n",
      "Supported Generation Methods: ['generateMessage', 'countMessageTokens']\n",
      "---\n",
      "Name: models/text-bison-001\n",
      "Display Name: PaLM 2 (Legacy)\n",
      "Supported Generation Methods: ['generateText', 'countTextTokens', 'createTunedTextModel']\n",
      "---\n",
      "Name: models/embedding-gecko-001\n",
      "Display Name: Embedding Gecko\n",
      "Supported Generation Methods: ['embedText', 'countTextTokens']\n",
      "---\n",
      "Name: models/gemini-1.0-pro-vision-latest\n",
      "Display Name: Gemini 1.0 Pro Vision\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-pro-vision\n",
      "Display Name: Gemini 1.0 Pro Vision\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-1.5-pro-latest\n",
      "Display Name: Gemini 1.5 Pro Latest\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-1.5-pro-001\n",
      "Display Name: Gemini 1.5 Pro 001\n",
      "Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "---\n",
      "Name: models/gemini-1.5-pro-002\n",
      "Display Name: Gemini 1.5 Pro 002\n",
      "Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "---\n",
      "Name: models/gemini-1.5-pro\n",
      "Display Name: Gemini 1.5 Pro\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-1.5-flash-latest\n",
      "Display Name: Gemini 1.5 Flash Latest\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-1.5-flash-001\n",
      "Display Name: Gemini 1.5 Flash 001\n",
      "Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "---\n",
      "Name: models/gemini-1.5-flash-001-tuning\n",
      "Display Name: Gemini 1.5 Flash 001 Tuning\n",
      "Supported Generation Methods: ['generateContent', 'countTokens', 'createTunedModel']\n",
      "---\n",
      "Name: models/gemini-1.5-flash\n",
      "Display Name: Gemini 1.5 Flash\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-1.5-flash-002\n",
      "Display Name: Gemini 1.5 Flash 002\n",
      "Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "---\n",
      "Name: models/gemini-1.5-flash-8b\n",
      "Display Name: Gemini 1.5 Flash-8B\n",
      "Supported Generation Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-1.5-flash-8b-001\n",
      "Display Name: Gemini 1.5 Flash-8B 001\n",
      "Supported Generation Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-1.5-flash-8b-latest\n",
      "Display Name: Gemini 1.5 Flash-8B Latest\n",
      "Supported Generation Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-1.5-flash-8b-exp-0827\n",
      "Display Name: Gemini 1.5 Flash 8B Experimental 0827\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-1.5-flash-8b-exp-0924\n",
      "Display Name: Gemini 1.5 Flash 8B Experimental 0924\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-2.5-pro-exp-03-25\n",
      "Display Name: Gemini 2.5 Pro Experimental 03-25\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-2.0-flash-exp\n",
      "Display Name: Gemini 2.0 Flash Experimental\n",
      "Supported Generation Methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "---\n",
      "Name: models/gemini-2.0-flash\n",
      "Display Name: Gemini 2.0 Flash\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-2.0-flash-001\n",
      "Display Name: Gemini 2.0 Flash 001\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-2.0-flash-exp-image-generation\n",
      "Display Name: Gemini 2.0 Flash (Image Generation) Experimental\n",
      "Supported Generation Methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "---\n",
      "Name: models/gemini-2.0-flash-lite-001\n",
      "Display Name: Gemini 2.0 Flash-Lite 001\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-2.0-flash-lite\n",
      "Display Name: Gemini 2.0 Flash-Lite\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-2.0-flash-lite-preview-02-05\n",
      "Display Name: Gemini 2.0 Flash-Lite Preview 02-05\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-2.0-flash-lite-preview\n",
      "Display Name: Gemini 2.0 Flash-Lite Preview\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-2.0-pro-exp\n",
      "Display Name: Gemini 2.0 Pro Experimental\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-2.0-pro-exp-02-05\n",
      "Display Name: Gemini 2.0 Pro Experimental 02-05\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-exp-1206\n",
      "Display Name: Gemini Experimental 1206\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-2.0-flash-thinking-exp-01-21\n",
      "Display Name: Gemini 2.0 Flash Thinking Experimental 01-21\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-2.0-flash-thinking-exp\n",
      "Display Name: Gemini 2.0 Flash Thinking Experimental 01-21\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemini-2.0-flash-thinking-exp-1219\n",
      "Display Name: Gemini 2.0 Flash Thinking Experimental\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/learnlm-1.5-pro-experimental\n",
      "Display Name: LearnLM 1.5 Pro Experimental\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemma-3-1b-it\n",
      "Display Name: Gemma 3 1B\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemma-3-4b-it\n",
      "Display Name: Gemma 3 4B\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemma-3-12b-it\n",
      "Display Name: Gemma 3 12B\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/gemma-3-27b-it\n",
      "Display Name: Gemma 3 27B\n",
      "Supported Generation Methods: ['generateContent', 'countTokens']\n",
      "---\n",
      "Name: models/embedding-001\n",
      "Display Name: Embedding 001\n",
      "Supported Generation Methods: ['embedContent']\n",
      "---\n",
      "Name: models/text-embedding-004\n",
      "Display Name: Text Embedding 004\n",
      "Supported Generation Methods: ['embedContent']\n",
      "---\n",
      "Name: models/gemini-embedding-exp-03-07\n",
      "Display Name: Gemini Embedding Experimental 03-07\n",
      "Supported Generation Methods: ['embedContent']\n",
      "---\n",
      "Name: models/gemini-embedding-exp\n",
      "Display Name: Gemini Embedding Experimental\n",
      "Supported Generation Methods: ['embedContent']\n",
      "---\n",
      "Name: models/aqa\n",
      "Display Name: Model that performs Attributed Question Answering.\n",
      "Supported Generation Methods: ['generateAnswer']\n",
      "---\n",
      "Name: models/imagen-3.0-generate-002\n",
      "Display Name: Imagen 3.0 002 model\n",
      "Supported Generation Methods: ['predict']\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Configure the API\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# List available models\n",
    "print(\"Available Models:\")\n",
    "for model in genai.list_models():\n",
    "    print(f\"Name: {model.name}\")\n",
    "    print(f\"Display Name: {model.display_name}\")\n",
    "    print(f\"Supported Generation Methods: {model.supported_generation_methods}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro-latest\",\n",
    "    temperature=0.4,\n",
    "    max_output_tokens=500,\n",
    "    google_api_key=GEMINI_API_KEY # Add this line\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='3d8a7ad8-9ba7-4ad8-bc36-8b995b2f3c70', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 38.0, 'page_label': '39', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data/Medical_book.pdf', 'total_pages': 637.0}, page_content='The goal of treating moderate acne is to decrease\\ninflammation and prevent new comedone formation. One\\neffective treatment is topical tretinoin along with a topical\\nGALE ENCYCLOPEDIA OF MEDICINE 2 25\\nAcne\\nAcne vulgaris affecting a woman’s face. Acne is the general\\nname given to a skin disorder in which the sebaceous\\nglands become inflamed.(Photograph by Biophoto Associ-\\nates, Photo Researchers, Inc. Reproduced by permission.)\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25'),\n",
       " Document(id='b5652f43-b3d6-4445-afaf-939cf6096fd2', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 37.0, 'page_label': '38', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data/Medical_book.pdf', 'total_pages': 637.0}, page_content='Description\\nAcne vulgaris, the medical term for common acne, is\\nthe most common skin disease. It affects nearly 17 million\\npeople in the United States. While acne can arise at any\\nage, it usually begins at puberty and worsens during ado-\\nlescence. Nearly 85% of people develop acne at some time\\nbetween the ages of 12-25 years. Up to 20% of women\\ndevelop mild acne. It is also found in some newborns.\\nThe sebaceous glands lie just beneath the skin’s sur-\\nface. They produce an oil called sebum, the skin’s natural\\nmoisturizer. These glands and the hair follicles within\\nwhich they are found are called sebaceous follicles.\\nThese follicles open onto the skin through pores. At\\npuberty, increased levels of androgens (male hormones)\\ncause the glands to produce too much sebum. When\\nexcess sebum combines with dead, sticky skin cells, a\\nhard plug, or comedo, forms that blocks the pore. Mild\\nnoninflammatory acne consists of the two types of come-\\ndones, whiteheads and blackheads.'),\n",
       " Document(id='7e68d6cc-ae6e-44ba-87f7-5ecbdbee64b4', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 37.0, 'page_label': '38', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data/Medical_book.pdf', 'total_pages': 637.0}, page_content='tranquilizers, antidepressants, antibiotics, oral contra-\\nceptives, and anabolic steroids.\\n• Personal hygiene. Abrasive soaps, hard scrubbing, or\\npicking at pimples will make them worse.\\n• Cosmetics. Oil-based makeup and hair sprays worsen\\nacne.\\n• Environment. Exposure to oils and greases, polluted air,\\nand sweating in hot weather aggravate acne.\\n• Stress. Emotional stress may contribute to acne.\\nAcne is usually not conspicuous, although inflamed\\nlesions may cause pain, tenderness, itching, or swelling.\\nThe most troubling aspects of these lesions are the nega-\\ntive cosmetic effects and potential for scarring. Some\\npeople, especially teenagers, become emotionally upset\\nabout their condition, and have problems forming rela-\\ntionships or keeping jobs.\\nDiagnosis\\nAcne patients are often treated by family doctors.\\nComplicated cases are referred to a dermatologist, a skin\\nGALE ENCYCLOPEDIA OF MEDICINE 224\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 24')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What is acne?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_pinecone import Pinecone\n",
    "from pinecone import Pinecone as PineconeClient\n",
    "\n",
    "\n",
    "\n",
    "def check_relevance(docs, query):\n",
    "    # If no documents or empty documents, return False\n",
    "    if not docs or not any(doc.page_content.strip() for doc in docs):\n",
    "        return False\n",
    "    \n",
    "    # Check if any document contains the exact query term\n",
    "    query_terms = query.lower().split()\n",
    "    for doc in docs:\n",
    "        content = doc.page_content.lower()\n",
    "        # Check if the exact query term is in the content\n",
    "        if any(term in content for term in query_terms):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Create a stricter prompt\n",
    "system_prompt = (\n",
    "    \"You are a medical assistant for question-answering tasks. \"\n",
    "    \"STRICTLY follow these rules:\\n\"\n",
    "    \"1. Use ONLY the provided medical context to answer\\n\"\n",
    "    \"2. If the context doesn't contain the answer, say: 'I don't have enough medical information to answer that.'\\n\"\n",
    "    \"3. Never make up, infer, or add information not explicitly stated\\n\"\n",
    "    \"4. If partial information exists, share ONLY what's explicitly mentioned\\n\"\n",
    "    \"5. Never reference similar or related topics if not directly asked\\n\"\n",
    "    \"6. Keep answers concise (2-3 sentences maximum)\\n\"\n",
    "    \"\\n\"\n",
    "    \"Context: {context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the document chain\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acromegaly is a disorder marked by increased bone and soft tissue growth, along with other bodily disturbances, caused by the abnormal release of growth hormone (GH) from the pituitary gland.  In children whose growth plates haven't closed, this leads to exceptional long bone growth, a variant called gigantism, causing unusual height. When the abnormality occurs after bone growth stops, it's called acromegaly. It affects roughly 50 out of every 1 million people, impacting both men and women.  Symptoms develop gradually, often delaying diagnosis until middle age.  The body's processing and use of nutrients like fats and sugars is also altered. Without treatment, it can lead to premature death due to effects on the heart, lungs, brain, or colon cancer. Treatment can enable a normal lifespan.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "response = rag_chain.invoke({\"input\": \"what is Acromegaly and gigantism?detailed explanation\"})\n",
    "print(response[\"answer\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have any relevant information about that topic in my medical database.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "response = rag_chain.invoke({\"input\": \"What is statistics?\"})\n",
    "print(response[\"answer\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
